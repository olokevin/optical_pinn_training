[basic]
device = cuda:0
experiment_name = 383134

[pretrained]
incre = False
load_model_path = /home/user_name/PINN/TensorFusionOperatorLearning/HJB_20d_FD/exp/dnn/False/0.999/gradients_auto_diff/adam/steplr/exp_1_gradNone_lr_1e-3/20230520-224054
pruned = False

[dataio]
batch_size = 100

[loss_func]
val_every = True
gradient_func = gradients_sparse_grid
sigma = 0.1

[model]
type = dnn
in_features = 21
out_features = 1
hidden_features = 512
num_layers = 3
nonlinearity = sine
nl_last_layer = False
fourier_mapping = False
bias = True
dtype

[training]
lr = 1e-3
epochs = 10000
epochs_til_checkpoints = 10000
start_epoch = 0
lr_decay = True
epochs_til_val = 100
verbose = False
random_state = 0
debug = False
optimizer = adam
scheduler = steplr
epochs_til_decay = 1000
gamma = 0.9

[validation]

[evaluation]
plot = True

[GraSP]
pruner = False
pruner_file = False
exception = -1
iterations = 1
normalize = false
target_ratio = 0.99
num_iters = 1

[ZO_Estim]
en = False
name = ZO_Estim_MC
sigma = 0.01
n_sample = 1
signsgd = False
scale = null
actv_perturb_layer_list = null
param_perturb_param_list = ['tt_factors', 'tt_voltages','bias', 'weight']
param_perturb_block_idx_list = all
obj_fn_type = pinn
quantized = False
en_layerwise_perturbation = True
en_partial_forward = False
en_param_commit = True
estimate_method = antithetic
sample_method = bernoulli
normalize_perturbation = False

